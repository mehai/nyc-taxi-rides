{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Yellow Taxi Rides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **data science** techniques and the open dataset from NYC's TLC, we've managed to discover some interesting insights in the way the Yellow Taxicabs operated in the first half of the year 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nyc, taxi, yellow-taxi, tlc, data-engineering, data-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NYC is popular for many things. One of these things is the yellow taxicab. They are widely recognizable symbols of the city. Taxis painted yellow (medallion taxis) are able to pick up passengers anywhere in the five boroughs. Taxicabs are operated by private companies and licensed by the New York City Taxi and Limousine Commission (TLC).\n",
    "\n",
    "Luckily for us, [TLC Trip Record Data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) is an open dataset which we can use to gain some interesting insights on how people in NYC use them.\n",
    "\n",
    "We are going to use a Data Science workflow to achieve our goals.\n",
    "\n",
    "**Data Acquisition --> Data Exploration --> Data Pre-processing --> Analysis**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Project Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this project is to apply *data science* techniques to discover useful insights in the data provided by NYC's TLC (Taxi & Limousine Commision) for the period January 2019 - June 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Source\n",
    "[TLC Trip Record Data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page)\n",
    "\n",
    "We are going to use the trip record data starting from January 2019 up to June 2019. We are also going to use the Taxi Zone Lookup Table also provided by this source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Description\n",
    "**A. TRIPS DATA**\n",
    "- **Files**: yellow_tripdata_2019-[01-06].csv (header included)\n",
    "- **Summary**: Each record models a yellow taxi trip.\n",
    "\n",
    "|**Column**|**Description**|\n",
    "|---|---|\n",
    "|VendorID|A code indicating the TPEP provider that provided the record. **<ul><li>1= Creative Mobile Technologies, LLC;</li> <li>2= VeriFone Inc. </li></ul>**|\n",
    "|tpep_pickup_datetime|The date and time when the meter was engaged.|\n",
    "|tpep_dropoff_datetime|The date and time when the meter was disengaged.|\n",
    "|passenger_count|The number of passengers in the vehicle. This is a driver-entered value.|\n",
    "|trip_distance|The elapsed trip distance in miles reported by the taximeter.|\n",
    "|RatecodeID|The final rate code in effect at the end of the trip. **<ul><li>1=Standard rate</li> <li>2=JFK</li> <li>3=Newark</li> <li>4=Nassau or Westchester</li><li>5=Negotiated fare</li> <li>6=Group ride</li></ul>**|\n",
    "|store_and_fwd_flag|This flag indicates whether the trip record was held in vehicle memory before sending to the vendor, aka “store and forward,” because the vehicle did not have a connection to the server. **<ul><li>Y=store and forward trip</li><li>N=not a store and forward trip</li></ul>**|\n",
    "|PULocationID|TLC Taxi Zone in which the taximeter was engaged|\n",
    "|DOLocationID|TLC Taxi Zone in which the taximeter was disengaged|\n",
    "|payment_type|A numeric code signifying how the passenger paid for the trip. **<ul><li>1=Credit card</li><li>2=Cash</li><li>3=No charge</li><li>4=Dispute</li><li>5=Unknown</li><li>6=Voided trip</li></ul>**|\n",
    "|fare_amount|The time-and-distance fare calculated by the meter.|\n",
    "|extra|Miscellaneous extras and surcharges.  Currently, this only includesthe 0.50 and 1 rush hour and overnight charges.|\n",
    "|mta_tax|0.50 MTA tax that is automatically triggered based on the metered rate in use.|\n",
    "|tip_amount|This field is automatically populated for credit card tips. Cash tips are not included.|\n",
    "|tolls_amount|Total amount of all tolls paid in trip.|\n",
    "|improvement_surcharge|0.30 improvement surcharge assessed trips at the flag drop.|\n",
    "|total_amount|The total amount charged to passengers. Does not include cash tips.|\n",
    "|congestion_surcharge|Surcharge in the case of congestion.|\n",
    "\n",
    "- **Details**:\n",
    "For further details please refer to the [trip record user guide](https://www1.nyc.gov/assets/tlc/downloads/pdf/trip_record_user_guide.pdf) and the [yellow trips data dictionary](https://www1.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf), both provided by TLC.\n",
    "\n",
    "**B. TAXI ZONE LOOKUP TABLE**\n",
    "- **Files**: taxi+_zone_lookup.csv (header included)\n",
    "- **Summary**: Each record models a taxi zone.\n",
    "\n",
    "|**Column**|**Description**|\n",
    "|---|---|\n",
    "|\"LocationID\"|ID of the location|\n",
    "|\"Borough\"|Borough in which the taxi zone is located|\n",
    "|\"Zone\"|Name of the zone|\n",
    "|\"service_zone\"|Type of zone, irrelevant for the yellow taxicabs as these are not restricted|\n",
    "\n",
    "- **Details**: For further details please refer to the [trip record user guide](https://www1.nyc.gov/assets/tlc/downloads/pdf/trip_record_user_guide.pdf) provided by TLC. Maps of the taxi zones for each borough can be found [here](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. The Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the current environment, only spark is installed so we need to also install the other tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.3.1-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.6 MB 343 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.15\n",
      "  Downloading numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=6.2.0\n",
      "  Downloading Pillow-7.2.0-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2020.6.20)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n",
      "Installing collected packages: numpy, kiwisolver, pillow, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.2.0 matplotlib-3.3.1 numpy-1.19.1 pillow-7.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.0-py3-none-any.whl (283 kB)\n",
      "\u001b[K     |████████████████████████████████| 283 kB 752 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas>=0.23\n",
      "  Downloading pandas-1.1.2-cp37-cp37m-manylinux1_x86_64.whl (10.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.5 MB 229 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=1.0\n",
      "  Downloading scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 13.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.3.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.19.1)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 5.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (7.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2020.6.20)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23->seaborn) (1.12.0)\n",
      "Installing collected packages: pytz, pandas, scipy, seaborn\n",
      "Successfully installed pandas-1.1.2 pytz-2020.1 scipy-1.5.2 seaborn-0.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  libpcre2-8-0\n",
      "The following NEW packages will be installed:\n",
      "  libpcre2-8-0 wget\n",
      "0 upgraded, 2 newly installed, 0 to remove and 0 not upgraded.\n",
      "Need to get 1115 kB of archives.\n",
      "After this operation, 3925 kB of additional disk space will be used.\n",
      "Get:1 http://deb.debian.org/debian buster/main amd64 libpcre2-8-0 amd64 10.32-5 [213 kB]\n",
      "Get:2 http://deb.debian.org/debian buster/main amd64 wget amd64 1.20.1-1.1 [902 kB]\n",
      "Fetched 1115 kB in 1s (1969 kB/s)\n",
      "Selecting previously unselected package libpcre2-8-0:amd64.\n",
      "(Reading database ... 27735 files and directories currently installed.)\n",
      "Preparing to unpack .../libpcre2-8-0_10.32-5_amd64.deb ...\n",
      "Unpacking libpcre2-8-0:amd64 (10.32-5) ...\n",
      "Selecting previously unselected package wget.\n",
      "Preparing to unpack .../wget_1.20.1-1.1_amd64.deb ...\n",
      "Unpacking wget (1.20.1-1.1) ...\n",
      "Setting up libpcre2-8-0:amd64 (10.32-5) ...\n",
      "Setting up wget (1.20.1-1.1) ...\n",
      "Processing triggers for libc-bin (2.28-10) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "debconf: delaying package configuration, since apt-utils is not installed\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "apt-get install --assume-yes wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to download the data. We are going to simply use wget to download the necessary csv files in a new directory called *nyc-taxi-data*.\n",
    "\n",
    "This might take a while as the total size of the data is almost 4GB. It is recommended not to run the next cell if you already have the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘nyc-taxi-data’: File exists\n",
      "2020-09-09 14:49:15 URL:https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-01.csv [687088084/687088084] -> \"nyc-taxi-data/yellow_tripdata_2019-01.csv\" [1]\n",
      "2020-09-09 15:03:47 URL:https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-02.csv [649882828/649882828] -> \"nyc-taxi-data/yellow_tripdata_2019-02.csv\" [1]\n",
      "2020-09-09 15:19:47 URL:https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-03.csv [726201566/726201566] -> \"nyc-taxi-data/yellow_tripdata_2019-03.csv\" [1]\n",
      "2020-09-09 15:30:28 URL:https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-04.csv [689207122/689207122] -> \"nyc-taxi-data/yellow_tripdata_2019-04.csv\" [1]\n",
      "2020-09-09 15:43:15 URL:https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-05.csv [701538890/701538890] -> \"nyc-taxi-data/yellow_tripdata_2019-05.csv\" [1]\n",
      "2020-09-09 15:53:22 URL:https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-06.csv [643492154/643492154] -> \"nyc-taxi-data/yellow_tripdata_2019-06.csv\" [1]\n",
      "2020-09-09 15:53:33 URL:https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv [12322/12322] -> \"nyc-taxi-data/taxi+_zone_lookup.csv\" [1]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir nyc-taxi-data\n",
    "wget -nv -P nyc-taxi-data https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-01.csv\n",
    "wget -nv -P nyc-taxi-data https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-02.csv\n",
    "wget -nv -P nyc-taxi-data https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-03.csv\n",
    "wget -nv -P nyc-taxi-data https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-04.csv\n",
    "wget -nv -P nyc-taxi-data https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-05.csv\n",
    "wget -nv -P nyc-taxi-data https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-06.csv\n",
    "wget -nv -P nyc-taxi-data https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we acquired the data, we need to get familiar with it, identify missing values, trends, outliers and check the veridicity of the documentation. This can help us understand the data better so that we know what alterations are needed in the next phase of Data Pre-Processing.\n",
    "\n",
    "Please note that there are other data exploration objectives like finding correlations between variabes. However, in this chapter we focus mainly on techniques that help us understand how we can clean and improve the data that we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before anything else, let's import the packages that we need and create the connection to the spark cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"nyc-taxi-app\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"1g\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's read the trips data from all 6 csv trip files in a single DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = spark.read.csv('nyc-taxi-data/yellow_tripdata_2019-*.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's have a look at the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: 18\n"
     ]
    }
   ],
   "source": [
    "print(f'Columns: {len(trips.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 44459136\n"
     ]
    }
   ],
   "source": [
    "print(f'Rows: {trips.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like there were **44.5 MILION** yellow taxi trips in NYC in the first 6 months of 2019.\n",
    "\n",
    "We can already see that the columns **extra**, **mta_tax**,**tolls_amount** and **improvement_surcharge** can be dropped later in the pre-processing stage as they do not provide much information for us and won't be useful for our purpose. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make use of the describe() function and identify if we have missing values and where they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+---------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+-------------------+------------------+------------------+-------------------+------------------+------------------+---------------------+------------------+--------------------+\n",
      "|summary|          VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|   passenger_count|    trip_distance|        RatecodeID|store_and_fwd_flag|      PULocationID|     DOLocationID|       payment_type|       fare_amount|             extra|            mta_tax|        tip_amount|      tolls_amount|improvement_surcharge|      total_amount|congestion_surcharge|\n",
      "+-------+------------------+--------------------+---------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+-------------------+------------------+------------------+-------------------+------------------+------------------+---------------------+------------------+--------------------+\n",
      "|  count|          44459136|            44459136|             44459136|          44459136|         44459136|          44459136|          44459136|          44459136|         44459136|           44459136|          44459136|          44459136|           44459136|          44459136|          44459136|             44459136|          44459136|            39603158|\n",
      "|   mean|1.6380644239240276|                null|                 null|1.5706694120191629|2.963478835710974|1.0597933797004062|              null|163.35420004563292|161.6743712248479| 1.2848562779087744| 13.10131723387516|1.0380626800754758|0.49576681089798946|2.1579379981649485|0.3686147578307025|  0.29892072350820736| 18.63620113265057|   2.102046755968299|\n",
      "| stddev|0.5152922204522865|                null|                 null|1.2228961598433996|7.909911727178382| 0.690014235007465|              null| 66.16360469053954|70.30454441602453|0.47437404774696734|222.90954945875015|1.2271497973859375|0.06625812216392685|21.397308654549015|1.7834713565753957| 0.024452401053206993|237.12281645476503|  0.9215726601608082|\n",
      "|    min|                 1| 2001-01-01 00:02:08|  2001-01-01 01:00:02|                 0|              0.0|                 1|                 N|                 1|                1|                  1|           -450.08|             -60.0|               -0.5|            -89.89|             -70.0|                 -0.3|           -450.88|                -2.5|\n",
      "|    max|                 4| 2088-01-24 00:25:39|  2088-01-24 07:28:25|                 9|         45977.22|                99|                 Y|               265|              265|                  5|          943274.8|            535.38|             212.42|         141492.02|            3288.0|                  1.0|        1084772.17|                 4.5|\n",
      "+-------+------------------+--------------------+---------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+-------------------+------------------+------------------+-------------------+------------------+------------------+---------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the only column with missing values seem to be **congestion_surcharge** which was to be expected as not all trips suffer congestion. However, the number of values in that column is still high (only 5M rows seem to have missing values) so we should expect to see many 0 values in that column.\n",
    "\n",
    "However, the **min** and **max** summaries give us more valuable information. There seem to be rows with corrupted values, e.g. datetimes in 2001 and 2088, negative or unrealistic amounts, invalid RatecodeIDs etc. These outliers need to be removed.\n",
    "\n",
    "Let's test some of our assumptions to see if they are true so that we know how to proceed next.\n",
    "First, let's check if there is a considerable amount of 0.0 in the congestion_surcharge column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6222601"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips.filter('congestion_surcharge = 0.0').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like only 6.2M rows have 0.0 congestion surcharge so our assumption wasn't true. It probably is common to have this surcharge in a nyc taxicab. So in order not to drop 5M rows which have this missing values and do not make our assumption that it was 0.0, we should fill the missing values with the mean for this column.\n",
    "\n",
    "Now, we know from the documentation provided by TLC that there are only 2 possible VendorID values, 1 and 2. However, before considering any different value an outlier, let's see weather or not there are other legitimate VendorIDs which were simply not documented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=1, count=16603925),\n",
       " Row(VendorID=4, count=256291),\n",
       " Row(VendorID=2, count=27598920)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips.groupBy('VendorID').count().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there is another Vendor with the ID of 4. Even if it accounts for only less than 0.01% of the data, we will still keep these observations as it is unrealistic to assume that 250000 rows are corrupted only because the VendorID differs.\n",
    "\n",
    "Now, let's do the same with the RatecodeID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(RatecodeID=1, count=42936836),\n",
       " Row(RatecodeID=6, count=288),\n",
       " Row(RatecodeID=3, count=90733),\n",
       " Row(RatecodeID=5, count=275287),\n",
       " Row(RatecodeID=4, count=32722),\n",
       " Row(RatecodeID=2, count=1121694),\n",
       " Row(RatecodeID=99, count=1576)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips.groupBy('RatecodeID').count().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be another RatecodeID=99. Since we don't know what this means and the number of rows with this RatecodeID is fairly low, we can simply modify these observations in the Pre-Processing stage to Unknown=5.\n",
    "\n",
    "Finally, let's check how many rows we will need to drop because they have negative or unrealistic amount values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67972"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips.filter('fare_amount < 0.0 or fare_amount > 100000.0 or tip_amount < 0.0 or total_amount < 0.0 or total_amount > 200000.0').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assumptions**:\n",
    "- There is another undocumented vendor with the VendorID of 4 which reported ~250000 trips.\n",
    "- The missing values in the congestion_surcharge are simply missing values.\n",
    "- The RatecodeID=99 is Unknown.\n",
    "- The fare_amount is in the range [0.0, 100000] and the total_amount in the range [0.0, 200000]. The rest of the values are corrupted / outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean & Transform Steps**:\n",
    "1. Drop extra, mta_tax,tolls_amount and improvement_surcharge columns;\n",
    "2. Switch type of datetime columns to timestamp\n",
    "3. Remove outlier rows: datetimes outside Jan - Jun 2019 | negative or unrealistcly high amounts | 0 trip_distance or passenger_count\n",
    "4. Fill missing values for congestion_surcharge with mean (assume there was 0.0 congestion surcharge in these cases)\n",
    "5. Modify RatecodeID=99 to 5 (Unknown)\n",
    "6. Integrate with the taxi zone lookup table to add 2 new columns: PUBorough and DOBorough\n",
    "7. Add a new column based on pickup_datetime: day_of_week (integer numbers from 1=Monday to 7=Sunday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Drop extra, mta_tax,tolls_amount and improvement_surcharge columns;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Switch type of datetime columns to timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Remove outlier rows: datetimes outside Jan - Jun 2019 | negative or unrealistcly high amounts | 0 trip_distance or passenger_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Fill missing values for congestion_surcharge with mean (assume there was 0.0 congestion surcharge in these cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Modify RatecodeID=99 to 5 (Unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Integrate with the taxi zone lookup table to add 2 new columns: PUBorough and DOBorough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Add a new column based on pickup_datetime: day_of_week (integer numbers from 1=Monday to 7=Sunday)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
